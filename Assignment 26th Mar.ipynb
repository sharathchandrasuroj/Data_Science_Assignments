{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0781943c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fedfb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160432d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b1089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629887cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e356ca1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c44a4fab",
   "metadata": {},
   "source": [
    "### Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdf73a7b",
   "metadata": {},
   "source": [
    "Simple linear regression is a statistical method used to model the relationship between a dependent variable and a single independent variable.\n",
    "\n",
    "It assumes that there is a linear relationship between the two variables, which can be represented by a straight line on a scatter plot. \n",
    "\n",
    "For example, one may want to investigate the relationship between a person's age and their weight.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b131da90",
   "metadata": {},
   "source": [
    "Multiple linear regression, on the other hand, is used to model the relationship between a dependent variable and two or more independent variables.\n",
    "It assumes that there is a linear relationship between the dependent variable and each independent variable, as well as an additive relationship\n",
    "between the independent variables themselves. For example, one may want to investigate the relationship between a person's salary and their age,\n",
    "education level, and years of experience.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a89cb03f",
   "metadata": {},
   "source": [
    "#An example of simple linear regression would be:\n",
    "\n",
    "-Suppose we want to study the relationship between the number of hours a student studies per week and their exam scores. \n",
    "\n",
    "-We collect data on 50 students and plot their hours of study against their exam scores on a scatter plot. \n",
    "\n",
    "-We find that there is a positive linear relationship between the two variables, indicating that as the number of hours studied increases, the exam scores also tend to increase. \n",
    "\n",
    "-Suppose we want to study the relationship between a car's fuel efficiency and its engine size, horsepower, and weight.\n",
    "\n",
    "-We collect data on 100 cars and plot their fuel efficiency against each of these three independent variables on a scatter plot.\n",
    "\n",
    "-We find that each of these independent variables has a significant linear relationship with fuel efficiency, and there may also be interactions between the variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f63f963",
   "metadata": {},
   "source": [
    "### Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc947ee7",
   "metadata": {},
   "source": [
    "There are several assumptions that underlie linear regression models. These assumptions are important because if they are violated, the resulting regression estimates may be biased or unreliable. Here are some of the key assumptions of linear regression:\n",
    "\n",
    "#Linearity:\n",
    "The relationship between the dependent variable and each independent variable is linear. This means that the regression equation should be a straight line.\n",
    "\n",
    "#Independence: The observations are independent of each other. This means that there is no systematic relationship between the residuals and any of the independent variables.\n",
    "\n",
    "#Homoscedasticity: The variance of the residuals is constant across all levels of the independent variable(s). This means that the scatter of the residuals should be approximately equal at all levels of the independent variable(s).\n",
    "\n",
    "#Normality: The residuals are normally distributed. This means that the distribution of the residuals should be approximately bell-shaped.\n",
    "\n",
    "#No multicollinearity: There is no perfect correlation between any two independent variables.\n",
    "\n",
    "#No influential outliers: There are no extreme values of the independent variable(s) that have a disproportionate impact on the regression line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e8a48d",
   "metadata": {},
   "source": [
    "### Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f0f41",
   "metadata": {},
   "source": [
    "In a linear regression model, the slope and intercept coefficients provide information about the relationship between the dependent variable and the independent variable(s).\n",
    "\n",
    "#The slope coefficient (often denoted as \"b\") represents the amount by which the dependent variable changes for a one-unit increase in the independent variable, holding all other variables constant. In other words, it represents the rate of change in the dependent variable for each unit change in the independent variable. A positive slope coefficient indicates a positive relationship between the variables, while a negative slope coefficient indicates a negative relationship.\n",
    "\n",
    "#The intercept coefficient (often denoted as \"a\") represents the predicted value of the dependent variable when all independent variables are zero.\n",
    "#In other words, it represents the value of the dependent variable when the independent variable has no effect.\n",
    "\n",
    "#Here is an example using a real-world scenario:\n",
    "\n",
    "#Suppose we want to investigate the relationship between a person's height and weight. We collect data on 100 people and fit a linear regression model with weight as the dependent variable and height as the independent variable. The resulting regression equation is:\n",
    "\n",
    "weight = 10 + 5(height) + error term\n",
    "\n",
    "#In this equation, the intercept coefficient (a) is 10, which means that a person who has a height of zero (which is not possible in reality) is predicted to have a weight of 10. The slope coefficient (b) is 5, which means that for every one-unit increase in height, the predicted weight increases by 5 pounds, holding all other variables constant. Therefore, a person who is one inch taller than another person is predicted to weigh 5 pounds more than the other person, on average.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5e2770",
   "metadata": {},
   "source": [
    "### Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbdf35e",
   "metadata": {},
   "source": [
    "#Gradient descent is an optimization algorithm used in machine learning to minimize the cost function of a model by adjusting the model's parameters iteratively. It is a first-order optimization algorithm that finds the minimum of a cost function by taking steps proportional to the negative of the gradient of the function.\n",
    "\n",
    "#The gradient is a vector that points in the direction of the steepest ascent of the function. By taking the negative of the gradient, we can move in the direction of the steepest descent of the function, which leads us towards the minimum.\n",
    "\n",
    "#In the context of machine learning, the cost function is a measure of how well the model fits the data. The goal of gradient descent is to adjust the model's parameters in such a way that the cost function is minimized, which means that the model is the best possible fit for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511fac02",
   "metadata": {},
   "source": [
    "### Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a77731",
   "metadata": {},
   "outputs": [],
   "source": [
    "Multiple linear regression is a statistical model that examines the linear relationship between a dependent variable and two or more independent\n",
    "variables. It is an extension of the simple linear regression model, which examines the relationship between a dependent variable and a single \n",
    "independent variable.\n",
    "\n",
    "#Number of independent variables: \n",
    "Simple linear regression has one independent variable, whereas multiple linear regression has two or \n",
    "more independent variables.\n",
    "\n",
    "#Interpretation of coefficients:\n",
    "In simple linear regression, the slope coefficient represents the change in the dependent variable associated\n",
    "#with a one-unit increase in the independent variable. In multiple linear regression, each slope coefficient represents the change in the dependent\n",
    "#variable associated with a one-unit increase in the corresponding independent variable, holding all other variables constant.\n",
    "\n",
    "#Model complexity:\n",
    "Multiple linear regression is a more complex model than simple linear regression because it includes two or more independent \n",
    "variables. As a result, it may be more difficult to interpret and may require more data to estimate accurately.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b59fb2",
   "metadata": {},
   "source": [
    "### Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c51414",
   "metadata": {},
   "source": [
    "Multicollinearity is a phenomenon that occurs when two or more independent variables in a multiple linear regression model are highly correlated with each other. This can lead to several issues in the analysis, including unstable and unreliable estimates of the regression coefficients, difficulty in interpreting the coefficients, and reduced predictive accuracy of the model.\n",
    "\n",
    "\n",
    "#Multicollinearity can be detected by examining the correlation matrix of the independent variables. A high correlation between two or more variables may indicate the presence of multicollinearity. Another way to detect multicollinearity is to calculate the variance inflation factor (VIF) for each independent variable. VIF measures the degree to which the variance of the estimated regression coefficient is increased due to multicollinearity.\n",
    "A VIF value of 1 indicates no multicollinearity, while values greater than 1 indicate increasing levels of multicollinearity.\n",
    "\n",
    "To address the issue of multicollinearity, several methods can be used, including:\n",
    "\n",
    "Dropping one or more highly correlated variables:\n",
    "If two or more variables are highly correlated, one of them can be dropped from the model to reduce the level of multicollinearity.\n",
    "\n",
    "Combining highly correlated variables: \n",
    "Instead of dropping one of the highly correlated variables, they can be combined into a single variable,such as a weighted average or principal component.\n",
    "\n",
    "Regularization techniques: \n",
    "Regularization techniques, such as ridge regression and lasso regression, can be used to shrink the regression coefficients towards zero, which can help reduce the impact of multicollinearity on the model.\n",
    "\n",
    "Collecting more data: Collecting more data can help reduce the impact of multicollinearity by increasing the sample size and reducing the correlation between the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ee3b59",
   "metadata": {},
   "source": [
    "### Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda461de",
   "metadata": {},
   "source": [
    "Polynomial regression is a form of regression analysis in which the relationship between the independent variable and dependent variable\n",
    "is modeled as an nth degree polynomial function. In other words, polynomial regression models assume that the relationship between the \n",
    "independent variable and dependent variable is not linear, but can be better described by a curved line or surface.\n",
    "\n",
    "Polynomial regression models are different from linear regression models in several ways:\n",
    "\n",
    "Functional form: The functional form of a polynomial regression model is a polynomial equation of degree n, while the functional form of a \n",
    "linear regression model is a straight line.\n",
    "\n",
    "Degree of complexity: Polynomial regression models are generally more complex than linear regression models, as they allow for a wider range \n",
    "of possible relationships between the independent and dependent variables.\n",
    "\n",
    "Flexibility: Polynomial regression models are more flexible than linear regression models in that they can capture nonlinear relationships \n",
    "between the independent and dependent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8df843b",
   "metadata": {},
   "source": [
    "### Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a84946a",
   "metadata": {},
   "source": [
    "#Advantages of polynomial regression over linear regression:\n",
    "\n",
    "#Flexibility: Polynomial regression models are more flexible than linear regression models as they can capture nonlinear relationships between\n",
    "the independent and dependent variables.\n",
    "\n",
    "#Better fit: In cases where the relationship between the independent and dependent variables is nonlinear, polynomial regression models\n",
    "can provide a better fit to the data compared to linear regression models.\n",
    "\n",
    "#Higher accuracy: In situations where the underlying relationship between the variables is a curve, polynomial regression models can provide \n",
    "higher accuracy compared to linear regression models.\n",
    "\n",
    "\n",
    "##Disadvantages of polynomial regression compared to linear regression:\n",
    "\n",
    "#Complexity: Polynomial regression models are more complex than linear regression models, as they require fitting higher order polynomial equations \n",
    "to the data.\n",
    "\n",
    "#Overfitting: Polynomial regression models are prone to overfitting, where the model fits the training data too closely and fails to generalize\n",
    "well to new data.\n",
    "\n",
    "#Interpretability: Polynomial regression models can be less interpretable compared to linear regression models, especially when the degree of\n",
    "the polynomial is high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5ae03e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c612e7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7ef1e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc64333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3194f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a38a07c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f91fbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4557f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6e20c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2f1a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e67dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
