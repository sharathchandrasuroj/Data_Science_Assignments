{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "334f974b",
   "metadata": {},
   "source": [
    "### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a1261",
   "metadata": {},
   "source": [
    "#Bayes' theorem is a mathematical formula that describes the probability of an event based on prior knowledge or information.\n",
    "\n",
    "#It was first formulated by the Reverend Thomas Bayes in the 18th century and has become a fundamental concept in probability theory and statistics.\n",
    "\n",
    "#The theorem states that the probability of an event A given event B can be calculated using the following formula:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "\n",
    "P(A) is the prior probability of event A occurring.\n",
    "\n",
    "P(B) is the prior probability of event B occurring.\n",
    "\n",
    "In other words, Bayes' theorem allows us to update our prior beliefs about the probability of an event occurring, based on new evidence.\n",
    "\n",
    "This makes it a powerful tool for decision-making and prediction, and it has applications in fields such as machine learning, medical diagnosis, and finance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26ad932",
   "metadata": {},
   "source": [
    "### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf13a504",
   "metadata": {},
   "source": [
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "\n",
    "P(A) is the prior probability of event A occurring.\n",
    "\n",
    "P(B) is the prior probability of event B occurring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3d53e3",
   "metadata": {},
   "source": [
    "### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b752dde",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice in many fields where uncertainty and probabilistic reasoning are involved, such as:\n",
    "\n",
    "**Medical diagnosis:** Bayes' theorem is used to calculate the probability of a patient having a particular disease, given their symptoms and \n",
    "test results.\n",
    "\n",
    "**Spam filtering:** Bayes' theorem is used to classify emails as spam or not spam, based on the probability of certain words or phrases appearing in\n",
    "the email.\n",
    "\n",
    "**Weather forecasting:** Bayes' theorem is used to update the probability of a particular weather condition occurring, based on new data such as\n",
    "temperature, pressure, and humidity.\n",
    "\n",
    "**Stock market analysis:** Bayes' theorem is used to estimate the probability of a stock price going up or down, based on past market trends and other \n",
    "relevant factors.\n",
    "\n",
    "**Image recognition:** Bayes' theorem is used to classify images into different categories based on the probability of certain features or patterns \n",
    "appearing in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb41aaf",
   "metadata": {},
   "source": [
    "### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7847b056",
   "metadata": {},
   "source": [
    "#Bayes' theorem and conditional probability are closely related concepts. Bayes' theorem is a mathematical formula that relates the conditional probability of an event A given event B to the conditional probability of event B given event A. In other words, it provides a way to calculate one conditional probability from the other.\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A given event B.\n",
    "\n",
    "P(B|A) is the conditional probability of event B given event A.\n",
    "\n",
    "P(A) is the prior probability of event A.\n",
    "\n",
    "P(B) is the prior probability of event B.\n",
    "\n",
    "Conditional probability is the probability of an event occurring given that another event has occurred. It is calculated by dividing the\n",
    "joint probability of the two events by the probability of the conditioning event.\n",
    "\n",
    "The formula for conditional probability is:\n",
    "\n",
    "P(A|B) = P(A and B) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the conditional probability of event A given event B.\n",
    "\n",
    "P(A and B) is the joint probability of events A and B occurring together.\n",
    "\n",
    "P(B) is the probability of event B occurring.\n",
    "\n",
    "Bayes' theorem can be seen as a special case of conditional probability, where the probabilities are updated based on new information or evidence.\n",
    "It provides a framework for updating our beliefs or probabilities about an event, given new evidence or information.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ef0e93",
   "metadata": {},
   "source": [
    "### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caf860e",
   "metadata": {},
   "source": [
    "#There are three main types of Naive Bayes classifiers: Gaussian Naive Bayes, Multinomial Naive Bayes, and Bernoulli Naive Bayes. \n",
    "The choice of which type of classifier to use depends on the nature of the problem and the type of data being used.\n",
    "\n",
    "**Gaussian Naive Bayes:** This classifier assumes that the input features follow a Gaussian distribution, i.e., they are continuous variables.\n",
    "\n",
    "It is typically used for classification problems where the input features are continuous or real-valued, such as in image recognition or natural language processing.\n",
    "\n",
    "**Multinomial Naive Bayes:** This classifier is used for problems where the input features are discrete, such as word frequencies in text classification.\n",
    "It assumes that the input features have a multinomial distribution, i.e., they represent the count or frequency of occurrences of each feature.\n",
    "\n",
    "**Bernoulli Naive Bayes:** This classifier is similar to Multinomial Naive Bayes but is used for binary or boolean inputs, where each feature represents a presence or absence of a particular feature. It is typically used in text classification problems where the input features are binary indicators, such as the presence or absence of certain words in a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9f4159",
   "metadata": {},
   "source": [
    "### Q6. Assignment: You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class: Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4 A 3 3 4 4 3 3 3 B 2 2 1 2 2 2 3 Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ede554",
   "metadata": {},
   "source": [
    "#To predict the class of a new instance with features X1=3 and X2=4, we need to calculate the posterior probabilities of the instance belonging to each class, given its feature values. We can use the Naive Bayes formula to calculate these probabilities:\n",
    "\n",
    "P(A | X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) / P(X1=3, X2=4)\n",
    "\n",
    "P(B | X1=3, X2=4) = P(X1=3, X2=4 | B) * P(B) / P(X1=3, X2=4)\n",
    "\n",
    "We can estimate the likelihood probabilities P(X1=3, X2=4 | A) and P(X1=3, X2=4 | B) from the frequency table:\n",
    "\n",
    "P(X1=3, X2=4 | A) = P(X1=3 | A) * P(X2=4 | A) = 4/13 * 3/13 = 12/169\n",
    "\n",
    "P(X1=3, X2=4 | B) = P(X1=3 | B) * P(X2=4 | B) = 1/7 * 3/7 = 3/49\n",
    "\n",
    "We can assume equal prior probabilities for each class, so P(A) = P(B) = 0.5. The marginal likelihood P(X1=3, X2=4) can be calculated using the law of total probability:\n",
    "\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) + P(X1=3, X2=4 | B) * P(B)= 12/169 * 0.5 + 3/49 * 0.5= 27/845\n",
    "\n",
    "Now we can substitute these values into the Naive Bayes formula:\n",
    "\n",
    "P(A | X1=3, X2=4) = 12/169 * 0.5 / (27/845) = 0.763\n",
    "\n",
    "P(B | X1=3, X2=4) = 3/49 * 0.5 / (27/845) = 0.237\n",
    "\n",
    "Therefore, Naive Bayes would predict the new instance to belong to class A, since it has a higher posterior probability.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d8740",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1053ab93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4dcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1515791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c510f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6f8495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5d126b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c86447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4b4e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d040ae82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1b1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003f8dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67514911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9533f042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb0c5fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26587230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab05235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe44e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d00bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
